SingleShotMaskDetector(
  (encoder): MobileViTv2(
    (conv_1): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=Swish)
    (layer_1): Sequential(
      (0): InvertedResidual(in_channels=24, out_channels=48, stride=1, exp=2, dilation=1, skip_conn=False)
    )
    (layer_2): Sequential(
      (0): InvertedResidual(in_channels=48, out_channels=96, stride=2, exp=2, dilation=1, skip_conn=False)
      (1): InvertedResidual(in_channels=96, out_channels=96, stride=1, exp=2, dilation=1, skip_conn=True)
    )
    (layer_3): Sequential(
      (0): InvertedResidual(in_channels=96, out_channels=192, stride=2, exp=2, dilation=1, skip_conn=False)
      (1): MobileViTBlockv2(
      	 Local representations
      		 Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False, normalization=BatchNorm2d, activation=Swish)
      		 Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      	 Global representations with patch size of 2x2
      		 LinearAttnFFN(embed_dim=96, ffn_dim=192, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=96, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LinearAttnFFN(embed_dim=96, ffn_dim=192, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=96, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LayerNorm2D_NCHW(num_channels=96, eps=1e-05, affine=True)
      		 Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False, normalization=BatchNorm2d)
      )
    )
    (layer_4): Sequential(
      (0): InvertedResidual(in_channels=192, out_channels=288, stride=2, exp=2, dilation=1, skip_conn=False)
      (1): MobileViTBlockv2(
      	 Local representations
      		 Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False, normalization=BatchNorm2d, activation=Swish)
      		 Conv2d(288, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
      	 Global representations with patch size of 2x2
      		 LinearAttnFFN(embed_dim=144, ffn_dim=288, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=144, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LinearAttnFFN(embed_dim=144, ffn_dim=288, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=144, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LinearAttnFFN(embed_dim=144, ffn_dim=288, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=144, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LinearAttnFFN(embed_dim=144, ffn_dim=288, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=144, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LayerNorm2D_NCHW(num_channels=144, eps=1e-05, affine=True)
      		 Conv2d(144, 288, kernel_size=(1, 1), stride=(1, 1), bias=False, normalization=BatchNorm2d)
      )
    )
    (layer_5): Sequential(
      (0): InvertedResidual(in_channels=288, out_channels=384, stride=2, exp=2, dilation=1, skip_conn=False)
      (1): MobileViTBlockv2(
      	 Local representations
      		 Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False, normalization=BatchNorm2d, activation=Swish)
      		 Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      	 Global representations with patch size of 2x2
      		 LinearAttnFFN(embed_dim=192, ffn_dim=384, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=192, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LinearAttnFFN(embed_dim=192, ffn_dim=384, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=192, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LinearAttnFFN(embed_dim=192, ffn_dim=384, dropout=0.0, ffn_dropout=0.0, attn_fn=LinearSelfAttention(embed_dim=192, attn_dropout=0.0), norm_layer=layer_norm_2d)
      		 LayerNorm2D_NCHW(num_channels=192, eps=1e-05, affine=True)
      		 Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False, normalization=BatchNorm2d)
      )
    )
    (conv_1x1_exp): None
    (classifier): None
  )
  (extra_layers): ModuleDict(
    (os_64): SeparableConv2d(in_channels=384, out_channels=256, kernel_size=3, stride=2, dilation=1)
    (os_128): SeparableConv2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, dilation=1)
    (os_256): SeparableConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, dilation=1)
    (os_-1): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, activation=ReLU)
    )
  )
  (anchor_box_generator): SSDAnchorGenerator(min_scale_ratio=0.1, max_scale_ratio=1.05, n_output_strides=6, n_aspect_ratios=6, clipping=True)
  (ssd_heads): ModuleList(
    (0): SSDHead(in_channels=512, n_anchors=6, n_classes=2, n_coordinates=4, kernel_size=3, stride=1, proj=True, proj_channels=512)
    (1): SSDHead(in_channels=256, n_anchors=6, n_classes=2, n_coordinates=4, kernel_size=3, stride=1, proj=True, proj_channels=256)
    (2): SSDHead(in_channels=256, n_anchors=6, n_classes=2, n_coordinates=4, kernel_size=3, stride=1)
    (3-4): 2 x SSDHead(in_channels=128, n_anchors=6, n_classes=2, n_coordinates=4, kernel_size=3, stride=1)
    (5): SSDHead(in_channels=64, n_anchors=4, n_classes=2, n_coordinates=4, kernel_size=1, stride=1)
  )
)